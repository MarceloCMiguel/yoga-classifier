{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir: ../data/DATASET\n",
      "os.listdir(dataset_dir): ['TRAIN', 'TEST']\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data'\n",
    "dataset_dir = os.path.join(data_dir, 'DATASET')\n",
    "\n",
    "print('data_dir:', dataset_dir)\n",
    "print('os.listdir(dataset_dir):', os.listdir(dataset_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "new_images_dir = os.path.join(data_dir, 'images')\n",
    "\n",
    "if os.path.exists(new_images_dir):\n",
    "    shutil.rmtree(new_images_dir)\n",
    "os.makedirs(new_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir_if_not_exists(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_dir: TRAIN\n",
      "|_sub_sub_dir: goddess\n",
      "|_sub_sub_dir: tree\n",
      "|_sub_sub_dir: downdog\n",
      "|_sub_sub_dir: plank\n",
      "|_sub_sub_dir: warrior2\n",
      "sub_dir: TEST\n",
      "|_sub_sub_dir: goddess\n",
      "|_sub_sub_dir: tree\n",
      "|_sub_sub_dir: downdog\n",
      "|_sub_sub_dir: plank\n",
      "|_sub_sub_dir: warrior2\n"
     ]
    }
   ],
   "source": [
    "targets_images = {} # example: {'godness': ['../data/images/godness/1.jpg', '../data/DATASET/godness/2.jpg', ...], ...}\n",
    "\n",
    "\n",
    "# enter in all the subdirectories of the dataset directory\n",
    "for sub_dir in os.listdir(dataset_dir):\n",
    "    print('sub_dir:', sub_dir)\n",
    "    sub_dir_path = os.path.join(dataset_dir, sub_dir)\n",
    "\n",
    "    # enter in all subdirectories of the sub_dir\n",
    "    for sub_sub_dir in os.listdir(sub_dir_path):\n",
    "        print('|_sub_sub_dir:', sub_sub_dir)\n",
    "        \n",
    "        if sub_sub_dir not in targets_images:\n",
    "            targets_images[sub_sub_dir] = []\n",
    "        \n",
    "        sub_sub_dir_path = os.path.join(sub_dir_path, sub_sub_dir)\n",
    "        new_sub_sub_dir = os.path.join(new_images_dir, sub_sub_dir)\n",
    "        create_dir_if_not_exists(new_sub_sub_dir)\n",
    "        \n",
    "        # enter in all the files of the sub_sub_dir\n",
    "        for file in os.listdir(sub_sub_dir_path):\n",
    "            file_path = os.path.join(sub_sub_dir_path, file)\n",
    "            new_file_path = os.path.join(new_sub_sub_dir, file)\n",
    "            if os.path.exists(new_file_path):\n",
    "                print('file already exists:', new_file_path)\n",
    "                continue\n",
    "            shutil.copy(file_path, new_file_path)\n",
    "            targets_images[sub_sub_dir].append(new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: goddess\n",
      "len(targets_images[key]): 260\n",
      "\n",
      "key: tree\n",
      "len(targets_images[key]): 229\n",
      "\n",
      "key: downdog\n",
      "len(targets_images[key]): 320\n",
      "\n",
      "key: plank\n",
      "len(targets_images[key]): 381\n",
      "\n",
      "key: warrior2\n",
      "len(targets_images[key]): 361\n",
      "\n",
      "count: 1551\n"
     ]
    }
   ],
   "source": [
    "targets_images.keys()\n",
    "count = 0\n",
    "for key in targets_images.keys():\n",
    "    print('key:', key)\n",
    "    print('len(targets_images[key]):', len(targets_images[key]))\n",
    "    print('')\n",
    "    count += len(targets_images[key])\n",
    "\n",
    "print('count:', count)\n",
    "\n",
    "def get_extension(file_path):\n",
    "    return file_path.split('.')[-1]\n",
    "\n",
    "def get_extensions(target):\n",
    "    extensions = {}\n",
    "    for target in targets_images.keys():\n",
    "        for image_path in targets_images[target]:\n",
    "            extension = get_extension(image_path)\n",
    "            if extension not in extensions:\n",
    "                extensions[extension] = 0\n",
    "            extensions[extension] += 1\n",
    "    return extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jpg': 1410, 'png': 110, 'JPG': 19, 'jpeg': 10, 'bmp': 1, 'PNG': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_extensions(targets_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming all extensions to lowercase\n",
    "for target in targets_images.keys():\n",
    "    for index, image_path in enumerate(targets_images[target]):\n",
    "        extension = get_extension(image_path)\n",
    "        lower_extension = extension.lower()\n",
    "        new_image_path = image_path.replace(extension,lower_extension)\n",
    "        os.rename(image_path,new_image_path)\n",
    "        targets_images[target][index] = new_image_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jpg': 1429, 'png': 111, 'jpeg': 10, 'bmp': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_extensions(targets_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# convert all images to jpg\n",
    "for target in targets_images.keys():\n",
    "    for index, image_path in enumerate(targets_images[target]):\n",
    "        extension = get_extension(image_path)\n",
    "        if extension == 'jpg':\n",
    "            continue\n",
    "        new_image_path = image_path.replace(extension, 'jpg')\n",
    "        im = Image.open(image_path)\n",
    "        rgb_im = im.convert(\"RGB\")\n",
    "        rgb_im.save(new_image_path)\n",
    "        os.remove(image_path)\n",
    "        targets_images[target][index] = new_image_path\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jpg': 1551}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_extensions(targets_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goddess 260 0.17%\n",
      "tree 229 0.15%\n",
      "downdog 320 0.21%\n",
      "plank 381 0.25%\n",
      "warrior2 361 0.23%\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for key, value in targets_images.items():\n",
    "    total += len(value)\n",
    "    \n",
    "for key, value in targets_images.items():\n",
    "    print(key, len(value), str(round(len(value)/total,2)) + \"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 11:09:06.871967: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-01 11:09:10.485593: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-01 11:09:10.489193: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-01 11:09:15.697594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for label, filenames in targets_images.items():\n",
    "    images.extend(filenames)\n",
    "    labels.extend([label] * len(filenames))\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Now you have your one-hot encoded labels ready for training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Image ../data/images/tree/00000114.jpg is truncated. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess images\n",
    "def load_and_preprocess_images(image_paths, labels):\n",
    "    X = []\n",
    "    filtered_labels = []\n",
    "\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        try:\n",
    "\n",
    "            img = load_img(image_path, target_size=(224, 224))\n",
    "            img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
    "            X.append(img_array)\n",
    "            filtered_labels.append(labels[i])\n",
    "        except OSError:\n",
    "            print(f\"Warning: Image {image_path} is truncated. Skipping...\")\n",
    "    return np.array(X), filtered_labels\n",
    "\n",
    "train_images_data, train_labels_filtered = load_and_preprocess_images(train_images, train_labels)\n",
    "test_images_data, test_labels_filtered = load_and_preprocess_images(test_images, test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LabelEncoder to convert labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "train_integer_encoded = label_encoder.fit_transform(train_labels_filtered)\n",
    "test_integer_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Use to_categorical to one-hot encode the integer-encoded labels\n",
    "train_one_hot_encoded = to_categorical(train_integer_encoded)\n",
    "test_one_hot_encoded = to_categorical(test_integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 11:09:53.598725: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 177209344 exceeds 10% of free system memory.\n",
      "2024-05-01 11:09:53.747330: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 177209344 exceeds 10% of free system memory.\n",
      "2024-05-01 11:09:53.794268: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 177209344 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               44302848  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,398,661\n",
      "Trainable params: 44,398,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define input shape of your images\n",
    "input_shape = (224, 224, 3)  # Assuming your images are RGB and 224x224 pixels\n",
    "\n",
    "# Create the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(targets_images), activation='softmax')  # Assuming len(data) is the number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 11:09:54.175299: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 746016768 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 11:09:56.943946: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 177209344 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 1.8048 - accuracy: 0.3398"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "      train_images_data, train_one_hot_encoded,\n",
    "      epochs=10,\n",
    "      validation_data=(test_images_data, test_one_hot_encoded))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_images_data, test_one_hot_encoded)\n",
    "print(f'Test accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(datagen):\n",
    "  # generate samples and plot\n",
    "  for i in range(9):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # generate batch of images\n",
    "    batch = datagen.next()\n",
    "    # convert to unsigned integers for viewing\n",
    "    image_ = batch[0]\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(image_[0])\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
